{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "# login to Sagemaker ECR with Deep Learning Containers\n",
    "!aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-2.amazonaws.com\n",
    "# login to your private ECR\n",
    "!aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 553020858742.dkr.ecr.us-east-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Use Sagemaker PyTorch container as base image\u001b[39;49;00m\n",
      "\u001b[37m# https://github.com/aws/sagemaker-pytorch-container/blob/master/docker/1.5.0/py3/Dockerfile.gpu\u001b[39;49;00m\n",
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33m763104351884.dkr.ecr.us-east-2.amazonaws.com/pytorch-training:1.5.0-gpu-py36-cu101-ubuntu16.04\u001b[39;49;00m\n",
      "\u001b[34mLABEL\u001b[39;49;00m \u001b[31mauthor\u001b[39;49;00m=\u001b[33m\"vadimd@amazon.com\"\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[37m############# Installing MMDetection from source ############\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /opt/ml/code\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install --upgrade --force-reinstall  torch torchvision cython\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install mmcv-full==latest+torch1.5.0+cu101 -f https://openmmlab.oss-accelerate.aliyuncs.com/mmcv/dist/index.html\n",
      "\n",
      "\u001b[34mRUN\u001b[39;49;00m git clone https://github.com/open-mmlab/mmdetection\n",
      "\u001b[34mRUN\u001b[39;49;00m \u001b[36mcd\u001b[39;49;00m mmdetection/ && \u001b[33m\\\u001b[39;49;00m\n",
      "    pip install -e .\n",
      "\n",
      "\u001b[37m# to address https://github.com/pytorch/pytorch/issues/37377\u001b[39;49;00m\n",
      "\u001b[34mENV\u001b[39;49;00m MKL_THREADING_LAYER GNU\n",
      "\n",
      "\u001b[37m############# Configuring Sagemaker ##############\u001b[39;49;00m\n",
      "\u001b[34mCOPY\u001b[39;49;00m container_training /opt/ml/code\n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      "\u001b[34mENV\u001b[39;49;00m SAGEMAKER_PROGRAM mmdetection_train.py\n",
      "\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /opt/ml/code/mmdetection\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Starts PyTorch distributed framework\u001b[39;49;00m\n",
      "\u001b[34mENTRYPOINT\u001b[39;49;00m [\u001b[33m\"bash\"\u001b[39;49;00m, \u001b[33m\"-m\"\u001b[39;49;00m, \u001b[33m\"start_with_right_hostname.sh\"\u001b[39;49;00m]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pygmentize -l docker Dockerfile.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  553.1MB\n",
      "Step 1/13 : FROM 763104351884.dkr.ecr.us-east-2.amazonaws.com/pytorch-training:1.5.0-gpu-py36-cu101-ubuntu16.04\n",
      " ---> 47cd15520b75\n",
      "Step 2/13 : LABEL author=\"vadimd@amazon.com\"\n",
      " ---> Using cache\n",
      " ---> 922dae94eea7\n",
      "Step 3/13 : WORKDIR /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 1e829cda7967\n",
      "Step 4/13 : RUN pip install --upgrade --force-reinstall  torch torchvision cython\n",
      " ---> Using cache\n",
      " ---> de5e1c07154c\n",
      "Step 5/13 : RUN pip install mmcv-full==latest+torch1.5.0+cu101 -f https://openmmlab.oss-accelerate.aliyuncs.com/mmcv/dist/index.html\n",
      " ---> Using cache\n",
      " ---> 73fa494e5c7a\n",
      "Step 6/13 : RUN git clone https://github.com/open-mmlab/mmdetection\n",
      " ---> Using cache\n",
      " ---> 57350fc7c079\n",
      "Step 7/13 : RUN cd mmdetection/ &&     pip install -e .\n",
      " ---> Using cache\n",
      " ---> b70d3e0c1052\n",
      "Step 8/13 : ENV MKL_THREADING_LAYER GNU\n",
      " ---> Using cache\n",
      " ---> 0f41a7766664\n",
      "Step 9/13 : ENV MMDETECTION /opt/ml/code/mmdetection\n",
      " ---> Using cache\n",
      " ---> 8b71c05d888c\n",
      "Step 10/13 : COPY container_training /opt/ml/code\n",
      " ---> 5fe51dfa5cfd\n",
      "Step 11/13 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Running in 47aacb4f4c20\n",
      "Removing intermediate container 47aacb4f4c20\n",
      " ---> 9d99a7f83a34\n",
      "Step 12/13 : ENV SAGEMAKER_PROGRAM mmdetection_train.py\n",
      " ---> Running in 62915aa45bf9\n",
      "Removing intermediate container 62915aa45bf9\n",
      " ---> 0fbe0455af4d\n",
      "Step 13/13 : WORKDIR /\n",
      " ---> Running in 5d0c89bed1b9\n",
      "Removing intermediate container 5d0c89bed1b9\n",
      " ---> 53965c4423d2\n",
      "Successfully built 53965c4423d2\n",
      "Successfully tagged mmdetection-training:latest\n",
      "The push refers to repository [553020858742.dkr.ecr.us-east-2.amazonaws.com/mmdetection-training]\n",
      "\n",
      "\u001b[1Be12d35b4: Preparing \n",
      "\u001b[1Beff3b448: Preparing \n",
      "\u001b[1B52d289f5: Preparing \n",
      "\u001b[1B552c64f8: Preparing \n",
      "\u001b[1B500d3ac7: Preparing \n",
      "\u001b[1B0eab7642: Preparing \n",
      "\u001b[1Bdc6eccf1: Preparing \n",
      "\u001b[1Be8cb8ead: Preparing \n",
      "\u001b[1B18b6f784: Preparing \n",
      "\u001b[1Bbe96fc82: Preparing \n",
      "\u001b[1B2b332e53: Preparing \n",
      "\u001b[1Bc6e1c93f: Preparing \n",
      "\u001b[1B8af0cced: Preparing \n",
      "\u001b[1Ba1e058e6: Preparing \n",
      "\u001b[1Ba7e2d141: Preparing \n",
      "\u001b[1B891256c7: Preparing \n",
      "\u001b[1B4275da12: Preparing \n",
      "\u001b[1B8601ef26: Preparing \n",
      "\u001b[1B03245374: Preparing \n",
      "\u001b[9Bc6e1c93f: Waiting g \n",
      "\u001b[15Bc6eccf1: Waiting g \n",
      "\u001b[10Baf0cced: Waiting g \n",
      "\u001b[1B3141886c: Preparing \n",
      "\u001b[17B8cb8ead: Waiting g \n",
      "\u001b[16Be96fc82: Waiting g \n",
      "\u001b[1Bdadd4466: Preparing \n",
      "\u001b[1B74e50f52: Preparing \n",
      "\u001b[20B8b6f784: Waiting g \n",
      "\u001b[1B74ebe255: Preparing \n",
      "\u001b[25Beab7642: Waiting g \n",
      "\u001b[17B7e2d141: Waiting g \n",
      "\u001b[1B103e78c9: Preparing \n",
      "\u001b[13B9ca2db2: Waiting g \n",
      "\u001b[34B12d35b4: Pushed lready exists kB31A\u001b[2K\u001b[33A\u001b[2K\u001b[23A\u001b[2K\u001b[18A\u001b[2K\u001b[14A\u001b[2K\u001b[9A\u001b[2K\u001b[2A\u001b[2K\u001b[34A\u001b[2Klatest: digest: sha256:0bbb7b3b541cbb10e42526da35fa2c91536ff9882072648837e905c2c213b560 size: 7472\n"
     ]
    }
   ],
   "source": [
    "! ./build_and_push.sh mmdetection-training latest Dockerfile.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "region = \"us-east-2\"\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "prefix_input = 'mmdetection-input'\n",
    "prefix_output = 'mmdetection-ouput'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = \"mmdetection-training\" # your container name\n",
    "tag = \"latest\"\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(account, region, container, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"config-file\" : \"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\n",
    "    \"dataset\" : \"coco\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Training in SM Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-25 22:32:10 Starting - Starting the training job...\n",
      "2020-07-25 22:32:12 Starting - Launching requested ML instances.........\n",
      "2020-07-25 22:33:48 Starting - Preparing the instances for training.........\n",
      "2020-07-25 22:35:28 Downloading - Downloading input data...................................................................................................\n",
      "2020-07-25 22:52:16 Training - Downloading the training image....................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:21,651 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:21,652 sagemaker-containers INFO     Failed to parse hyperparameter config-file value configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:21,653 sagemaker-containers INFO     Failed to parse hyperparameter dataset value coco to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:21,731 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:21,204 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:21,205 sagemaker-containers INFO     Failed to parse hyperparameter config-file value configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:21,205 sagemaker-containers INFO     Failed to parse hyperparameter dataset value coco to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:21,283 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:24,303 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:24,712 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:24,712 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:24,712 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:24,713 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:24,746 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:25,175 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:25,176 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:25,176 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:25,176 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /tmp/tmp2ihhwaz0/module_dir\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpotad8woa/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[35m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=18943071 sha256=b64bf4d138c9690ca6d7e19663365308fd2251cbd46ede1322cb32a233ac3e67\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-t61h8a3v/wheels/14/4f/1e/807485dde9e4914a1ba28ac18acbd249eb0141ce5398cb793c\u001b[0m\n",
      "\u001b[35mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=18943071 sha256=f24a970508e00000f6d9ea2482a33fc992273219d6452923dadb0a9fd488659b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nh1kj8n0/wheels/e9/b3/c3/cb185cfe75f6ab1b75bb076cd91c1b9a44fb92d947caf4c3cb\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[35mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[35mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[35mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\u001b[0m\n",
      "\u001b[35mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:29,397 sagemaker-containers INFO     Failed to parse hyperparameter config-file value configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:29,397 sagemaker-containers INFO     Failed to parse hyperparameter dataset value coco to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:29,411 sagemaker-containers INFO     Failed to parse hyperparameter config-file value configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:29,411 sagemaker-containers INFO     Failed to parse hyperparameter dataset value coco to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:29,492 sagemaker-containers INFO     Failed to parse hyperparameter config-file value configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:29,492 sagemaker-containers INFO     Failed to parse hyperparameter dataset value coco to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m2020-07-25 22:55:29,570 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[35mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config-file\": \"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\n",
      "        \"dataset\": \"coco\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"mmdetection-training-2020-07-25-22-32-10-282\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"mmdetection_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mmdetection_train.py\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"config-file\":\"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\"dataset\":\"coco\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=mmdetection_train.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=mmdetection_train\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"config-file\":\"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\"dataset\":\"coco\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"mmdetection-training-2020-07-25-22-32-10-282\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"mmdetection_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mmdetection_train.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--config-file\",\"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\"--dataset\",\"coco\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_CONFIG-FILE=configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\u001b[0m\n",
      "\u001b[35mSM_HP_DATASET=coco\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages:/opt/ml/code/mmdetection\n",
      "\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python mmdetection_train.py --config-file configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py --dataset coco\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:30,073 sagemaker-containers INFO     Failed to parse hyperparameter config-file value configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:30,074 sagemaker-containers INFO     Failed to parse hyperparameter dataset value coco to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:30,087 sagemaker-containers INFO     Failed to parse hyperparameter config-file value configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:30,088 sagemaker-containers INFO     Failed to parse hyperparameter dataset value coco to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:30,168 sagemaker-containers INFO     Failed to parse hyperparameter config-file value configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:30,168 sagemaker-containers INFO     Failed to parse hyperparameter dataset value coco to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:30,246 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config-file\": \"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\n",
      "        \"dataset\": \"coco\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"mmdetection-training-2020-07-25-22-32-10-282\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"mmdetection_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mmdetection_train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"config-file\":\"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\"dataset\":\"coco\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mmdetection_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mmdetection_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"config-file\":\"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\"dataset\":\"coco\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mmdetection-training-2020-07-25-22-32-10-282\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"mmdetection_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mmdetection_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--config-file\",\"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\"--dataset\",\"coco\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_CONFIG-FILE=configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET=coco\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages:/opt/ml/code/mmdetection\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python mmdetection_train.py --config-file configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py --dataset coco\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "2020-07-25 22:55:20 Training - Training image download completed. Training in progress.\u001b[35mStarting training...\u001b[0m\n",
      "\u001b[35mWill use config from file /opt/ml/code/mmdetection/configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\u001b[0m\n",
      "\u001b[35mDEBUG \n",
      " data root ['val2017', 'annotations', 'train2017']\u001b[0m\n",
      "\u001b[34mStarting training...\u001b[0m\n",
      "\u001b[34mWill use config from file /opt/ml/code/mmdetection/configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\u001b[0m\n",
      "\u001b[34mDEBUG \n",
      " data root ['train2017', 'val2017', 'annotations']\u001b[0m\n",
      "\u001b[35mFollowing config will be used for training:model = dict(\n",
      "    type='MaskRCNN',\n",
      "    pretrained='torchvision://resnet50',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch'),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=80,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        mask_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        mask_head=dict(\n",
      "            type='FCNMaskHead',\n",
      "            num_convs=4,\n",
      "            in_channels=256,\n",
      "            conv_out_channels=256,\n",
      "            num_classes=80,\n",
      "            loss_mask=dict(\n",
      "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))))\u001b[0m\n",
      "\u001b[35mtrain_cfg = dict(\n",
      "    rpn=dict(\n",
      "        assigner=dict(\n",
      "            type='MaxIoUAssigner',\n",
      "            pos_iou_thr=0.7,\n",
      "            neg_iou_thr=0.3,\n",
      "            min_pos_iou=0.3,\n",
      "            match_low_quality=True,\n",
      "            ignore_iof_thr=-1),\n",
      "        sampler=dict(\n",
      "            type='RandomSampler',\n",
      "            num=256,\n",
      "            pos_fraction=0.5,\n",
      "            neg_pos_ub=-1,\n",
      "            add_gt_as_proposals=False),\n",
      "        allowed_border=-1,\n",
      "        pos_weight=-1,\n",
      "        debug=False),\n",
      "    rpn_proposal=dict(\n",
      "        nms_across_levels=False,\n",
      "        nms_pre=2000,\n",
      "        nms_post=1000,\n",
      "        max_num=1000,\n",
      "        nms_thr=0.7,\n",
      "        min_bbox_size=0),\n",
      "    rcnn=dict(\n",
      "        assigner=dict(\n",
      "            type='MaxIoUAssigner',\n",
      "            pos_iou_thr=0.5,\n",
      "            neg_iou_thr=0.5,\n",
      "            min_pos_iou=0.5,\n",
      "            match_low_quality=True,\n",
      "            ignore_iof_thr=-1),\n",
      "        sampler=dict(\n",
      "            type='RandomSampler',\n",
      "            num=512,\n",
      "            pos_fraction=0.25,\n",
      "            neg_pos_ub=-1,\n",
      "            add_gt_as_proposals=True),\n",
      "        mask_size=28,\n",
      "        pos_weight=-1,\n",
      "        debug=False))\u001b[0m\n",
      "\u001b[35mtest_cfg = dict(\n",
      "    rpn=dict(\n",
      "        nms_across_levels=False,\n",
      "        nms_pre=1000,\n",
      "        nms_post=1000,\n",
      "        max_num=1000,\n",
      "        nms_thr=0.7,\n",
      "        min_bbox_size=0),\n",
      "    rcnn=dict(\n",
      "        score_thr=0.05,\n",
      "        nms=dict(type='nms', iou_threshold=0.5),\n",
      "        max_per_img=100,\n",
      "        mask_thr_binary=0.5))\u001b[0m\n",
      "\u001b[35mdataset_type = 'CocoDataset'\u001b[0m\n",
      "\u001b[35mdata_root = '/opt/ml/input/data/training'\u001b[0m\n",
      "\u001b[35mimg_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\u001b[0m\n",
      "\u001b[35mtrain_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\u001b[0m\n",
      "\u001b[35m]\u001b[0m\n",
      "\u001b[35mtest_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\u001b[0m\n",
      "\u001b[35m]\u001b[0m\n",
      "\u001b[35mdata = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file=\n",
      "        '/opt/ml/input/data/training/annotations/instances_train2017.json',\n",
      "        img_prefix='/opt/ml/input/data/training/train2017',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file=\n",
      "        '/opt/ml/input/data/training/annotations/instances_val2017.json',\n",
      "        img_prefix='/opt/ml/input/data/training/val2017',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file=\n",
      "        '/opt/ml/input/data/training/annotations/instances_val2017.json',\n",
      "        img_prefix='/opt/ml/input/data/training/val2017',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\u001b[0m\n",
      "\u001b[35mevaluation = dict(metric=['bbox', 'segm'])\u001b[0m\n",
      "\u001b[35moptimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\u001b[0m\n",
      "\u001b[35moptimizer_config = dict(grad_clip=None)\u001b[0m\n",
      "\u001b[35mlr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\u001b[0m\n",
      "\u001b[35mtotal_epochs = 12\u001b[0m\n",
      "\u001b[35mcheckpoint_config = dict(interval=1)\u001b[0m\n",
      "\u001b[35mlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\u001b[0m\n",
      "\u001b[35mdist_params = dict(backend='nccl')\u001b[0m\n",
      "\u001b[35mlog_level = 'INFO'\u001b[0m\n",
      "\u001b[35mload_from = None\u001b[0m\n",
      "\u001b[35mresume_from = None\u001b[0m\n",
      "\u001b[35mworkflow = [('train', 1)]\n",
      "\u001b[0m\n",
      "\u001b[35mFollowing command will be executed: \n",
      " python -m torch.distributed.launch --nnodes 2 --node_rank 1 --nproc_per_node 8 --master_addr algo-1 --master_port 55555 /opt/ml/code/mmdetection/tools/train.py /opt/ml/code/updated_config.py --launcher pytorch\u001b[0m\n",
      "\u001b[34mFollowing config will be used for training:model = dict(\n",
      "    type='MaskRCNN',\n",
      "    pretrained='torchvision://resnet50',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch'),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=80,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        mask_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        mask_head=dict(\n",
      "            type='FCNMaskHead',\n",
      "            num_convs=4,\n",
      "            in_channels=256,\n",
      "            conv_out_channels=256,\n",
      "            num_classes=80,\n",
      "            loss_mask=dict(\n",
      "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))))\u001b[0m\n",
      "\u001b[34mtrain_cfg = dict(\n",
      "    rpn=dict(\n",
      "        assigner=dict(\n",
      "            type='MaxIoUAssigner',\n",
      "            pos_iou_thr=0.7,\n",
      "            neg_iou_thr=0.3,\n",
      "            min_pos_iou=0.3,\n",
      "            match_low_quality=True,\n",
      "            ignore_iof_thr=-1),\n",
      "        sampler=dict(\n",
      "            type='RandomSampler',\n",
      "            num=256,\n",
      "            pos_fraction=0.5,\n",
      "            neg_pos_ub=-1,\n",
      "            add_gt_as_proposals=False),\n",
      "        allowed_border=-1,\n",
      "        pos_weight=-1,\n",
      "        debug=False),\n",
      "    rpn_proposal=dict(\n",
      "        nms_across_levels=False,\n",
      "        nms_pre=2000,\n",
      "        nms_post=1000,\n",
      "        max_num=1000,\n",
      "        nms_thr=0.7,\n",
      "        min_bbox_size=0),\n",
      "    rcnn=dict(\n",
      "        assigner=dict(\n",
      "            type='MaxIoUAssigner',\n",
      "            pos_iou_thr=0.5,\n",
      "            neg_iou_thr=0.5,\n",
      "            min_pos_iou=0.5,\n",
      "            match_low_quality=True,\n",
      "            ignore_iof_thr=-1),\n",
      "        sampler=dict(\n",
      "            type='RandomSampler',\n",
      "            num=512,\n",
      "            pos_fraction=0.25,\n",
      "            neg_pos_ub=-1,\n",
      "            add_gt_as_proposals=True),\n",
      "        mask_size=28,\n",
      "        pos_weight=-1,\n",
      "        debug=False))\u001b[0m\n",
      "\u001b[34mtest_cfg = dict(\n",
      "    rpn=dict(\n",
      "        nms_across_levels=False,\n",
      "        nms_pre=1000,\n",
      "        nms_post=1000,\n",
      "        max_num=1000,\n",
      "        nms_thr=0.7,\n",
      "        min_bbox_size=0),\n",
      "    rcnn=dict(\n",
      "        score_thr=0.05,\n",
      "        nms=dict(type='nms', iou_threshold=0.5),\n",
      "        max_per_img=100,\n",
      "        mask_thr_binary=0.5))\u001b[0m\n",
      "\u001b[34mdataset_type = 'CocoDataset'\u001b[0m\n",
      "\u001b[34mdata_root = '/opt/ml/input/data/training'\u001b[0m\n",
      "\u001b[34mimg_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\u001b[0m\n",
      "\u001b[34mtrain_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\u001b[0m\n",
      "\u001b[34m]\u001b[0m\n",
      "\u001b[34mtest_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\u001b[0m\n",
      "\u001b[34m]\u001b[0m\n",
      "\u001b[34mdata = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file=\n",
      "        '/opt/ml/input/data/training/annotations/instances_train2017.json',\n",
      "        img_prefix='/opt/ml/input/data/training/train2017',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file=\n",
      "        '/opt/ml/input/data/training/annotations/instances_val2017.json',\n",
      "        img_prefix='/opt/ml/input/data/training/val2017',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file=\n",
      "        '/opt/ml/input/data/training/annotations/instances_val2017.json',\n",
      "        img_prefix='/opt/ml/input/data/training/val2017',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\u001b[0m\n",
      "\u001b[34mevaluation = dict(metric=['bbox', 'segm'])\u001b[0m\n",
      "\u001b[34moptimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\u001b[0m\n",
      "\u001b[34moptimizer_config = dict(grad_clip=None)\u001b[0m\n",
      "\u001b[34mlr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\u001b[0m\n",
      "\u001b[34mtotal_epochs = 12\u001b[0m\n",
      "\u001b[34mcheckpoint_config = dict(interval=1)\u001b[0m\n",
      "\u001b[34mlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\u001b[0m\n",
      "\u001b[34mdist_params = dict(backend='nccl')\u001b[0m\n",
      "\u001b[34mlog_level = 'INFO'\u001b[0m\n",
      "\u001b[34mload_from = None\u001b[0m\n",
      "\u001b[34mresume_from = None\u001b[0m\n",
      "\u001b[34mworkflow = [('train', 1)]\n",
      "\u001b[0m\n",
      "\u001b[34mFollowing command will be executed: \n",
      " python -m torch.distributed.launch --nnodes 2 --node_rank 0 --nproc_per_node 8 --master_addr algo-1 --master_port 55555 /opt/ml/code/mmdetection/tools/train.py /opt/ml/code/updated_config.py --launcher pytorch\u001b[0m\n",
      "\u001b[35m*****************************************\u001b[0m\n",
      "\u001b[35mSetting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\u001b[0m\n",
      "\u001b[35m*****************************************\u001b[0m\n",
      "\u001b[34m*****************************************\u001b[0m\n",
      "\u001b[34mSetting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\u001b[0m\n",
      "\u001b[34m*****************************************\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:41,684 - mmdet - INFO - Environment info:\u001b[0m\n",
      "\u001b[34m------------------------------------------------------------\u001b[0m\n",
      "\u001b[34msys.platform: linux\u001b[0m\n",
      "\u001b[34mPython: 3.6.6 |Anaconda, Inc.| (default, Oct  9 2018, 12:34:16) [GCC 7.3.0]\u001b[0m\n",
      "\u001b[34mCUDA available: True\u001b[0m\n",
      "\u001b[34mCUDA_HOME: /usr/local/cuda\u001b[0m\n",
      "\u001b[34mNVCC: Cuda compilation tools, release 10.1, V10.1.243\u001b[0m\n",
      "\u001b[34mGPU 0,1,2,3,4,5,6,7: Tesla V100-SXM2-16GB\u001b[0m\n",
      "\u001b[34mGCC: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\u001b[0m\n",
      "\u001b[34mPyTorch: 1.5.1\u001b[0m\n",
      "\u001b[34mPyTorch compiling details: PyTorch built with:\u001b[0m\n",
      "\u001b[34m- GCC 7.3\u001b[0m\n",
      "\u001b[34m- C++ Version: 201402\u001b[0m\n",
      "\u001b[34m- Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\u001b[0m\n",
      "\u001b[34m- Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\u001b[0m\n",
      "\u001b[34m- OpenMP 201511 (a.k.a. OpenMP 4.5)\u001b[0m\n",
      "\u001b[34m- NNPACK is enabled\u001b[0m\n",
      "\u001b[34m- CPU capability usage: AVX2\u001b[0m\n",
      "\u001b[34m- CUDA Runtime 10.2\u001b[0m\n",
      "\u001b[34m- NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\u001b[0m\n",
      "\u001b[34m- CuDNN 7.6.5\u001b[0m\n",
      "\u001b[34m- Magma 2.5.2\u001b[0m\n",
      "\u001b[34m- Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,\n",
      "\u001b[0m\n",
      "\u001b[34mTorchVision: 0.6.1\u001b[0m\n",
      "\u001b[34mOpenCV: 4.3.0\u001b[0m\n",
      "\u001b[34mMMCV: 1.0.3\u001b[0m\n",
      "\u001b[34mMMDetection: 2.3.0rc0+c24d52c\u001b[0m\n",
      "\u001b[34mMMDetection Compiler: GCC 7.3\u001b[0m\n",
      "\u001b[34mMMDetection CUDA Compiler: 10.1\u001b[0m\n",
      "\u001b[34m------------------------------------------------------------\n",
      "\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:41,684 - mmdet - INFO - Distributed training: True\u001b[0m\n",
      "\u001b[35mDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:42,851 - mmdet - INFO - Config:\u001b[0m\n",
      "\u001b[34mmodel = dict(\u001b[0m\n",
      "\u001b[34mtype='MaskRCNN',\u001b[0m\n",
      "\u001b[34mpretrained='torchvision://resnet50',\u001b[0m\n",
      "\u001b[34mbackbone=dict(\u001b[0m\n",
      "\u001b[34mtype='ResNet',\u001b[0m\n",
      "\u001b[34mdepth=50,\u001b[0m\n",
      "\u001b[34mnum_stages=4,\u001b[0m\n",
      "\u001b[34mout_indices=(0, 1, 2, 3),\u001b[0m\n",
      "\u001b[34mfrozen_stages=1,\u001b[0m\n",
      "\u001b[34mnorm_cfg=dict(type='BN', requires_grad=True),\u001b[0m\n",
      "\u001b[34mnorm_eval=True,\u001b[0m\n",
      "\u001b[34mstyle='pytorch'),\u001b[0m\n",
      "\u001b[34mneck=dict(\u001b[0m\n",
      "\u001b[34mtype='FPN',\u001b[0m\n",
      "\u001b[34min_channels=[256, 512, 1024, 2048],\u001b[0m\n",
      "\u001b[34mout_channels=256,\u001b[0m\n",
      "\u001b[34mnum_outs=5),\u001b[0m\n",
      "\u001b[34mrpn_head=dict(\u001b[0m\n",
      "\u001b[34mtype='RPNHead',\u001b[0m\n",
      "\u001b[34min_channels=256,\u001b[0m\n",
      "\u001b[34mfeat_channels=256,\u001b[0m\n",
      "\u001b[34manchor_generator=dict(\u001b[0m\n",
      "\u001b[34mtype='AnchorGenerator',\u001b[0m\n",
      "\u001b[34mscales=[8],\u001b[0m\n",
      "\u001b[34mratios=[0.5, 1.0, 2.0],\u001b[0m\n",
      "\u001b[34mstrides=[4, 8, 16, 32, 64]),\u001b[0m\n",
      "\u001b[34mbbox_coder=dict(\u001b[0m\n",
      "\u001b[34mtype='DeltaXYWHBBoxCoder',\u001b[0m\n",
      "\u001b[34mtarget_means=[0.0, 0.0, 0.0, 0.0],\u001b[0m\n",
      "\u001b[34mtarget_stds=[1.0, 1.0, 1.0, 1.0]),\u001b[0m\n",
      "\u001b[34mloss_cls=dict(\u001b[0m\n",
      "\u001b[34mtype='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\u001b[0m\n",
      "\u001b[34mloss_bbox=dict(type='L1Loss', loss_weight=1.0)),\u001b[0m\n",
      "\u001b[34mroi_head=dict(\u001b[0m\n",
      "\u001b[34mtype='StandardRoIHead',\u001b[0m\n",
      "\u001b[34mbbox_roi_extractor=dict(\u001b[0m\n",
      "\u001b[34mtype='SingleRoIExtractor',\u001b[0m\n",
      "\u001b[34mroi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\u001b[0m\n",
      "\u001b[34mout_channels=256,\u001b[0m\n",
      "\u001b[34mfeatmap_strides=[4, 8, 16, 32]),\u001b[0m\n",
      "\u001b[34mbbox_head=dict(\u001b[0m\n",
      "\u001b[34mtype='Shared2FCBBoxHead',\u001b[0m\n",
      "\u001b[34min_channels=256,\u001b[0m\n",
      "\u001b[34mfc_out_channels=1024,\u001b[0m\n",
      "\u001b[34mroi_feat_size=7,\u001b[0m\n",
      "\u001b[34mnum_classes=80,\u001b[0m\n",
      "\u001b[34mbbox_coder=dict(\u001b[0m\n",
      "\u001b[34mtype='DeltaXYWHBBoxCoder',\u001b[0m\n",
      "\u001b[34mtarget_means=[0.0, 0.0, 0.0, 0.0],\u001b[0m\n",
      "\u001b[34mtarget_stds=[0.1, 0.1, 0.2, 0.2]),\u001b[0m\n",
      "\u001b[34mreg_class_agnostic=False,\u001b[0m\n",
      "\u001b[34mloss_cls=dict(\u001b[0m\n",
      "\u001b[34mtype='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\u001b[0m\n",
      "\u001b[34mloss_bbox=dict(type='L1Loss', loss_weight=1.0)),\u001b[0m\n",
      "\u001b[34mmask_roi_extractor=dict(\u001b[0m\n",
      "\u001b[34mtype='SingleRoIExtractor',\u001b[0m\n",
      "\u001b[34mroi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\u001b[0m\n",
      "\u001b[34mout_channels=256,\u001b[0m\n",
      "\u001b[34mfeatmap_strides=[4, 8, 16, 32]),\u001b[0m\n",
      "\u001b[34mmask_head=dict(\u001b[0m\n",
      "\u001b[34mtype='FCNMaskHead',\u001b[0m\n",
      "\u001b[34mnum_convs=4,\u001b[0m\n",
      "\u001b[34min_channels=256,\u001b[0m\n",
      "\u001b[34mconv_out_channels=256,\u001b[0m\n",
      "\u001b[34mnum_classes=80,\u001b[0m\n",
      "\u001b[34mloss_mask=dict(\u001b[0m\n",
      "\u001b[34mtype='CrossEntropyLoss', use_mask=True, loss_weight=1.0))))\u001b[0m\n",
      "\u001b[34mtrain_cfg = dict(\u001b[0m\n",
      "\u001b[34mrpn=dict(\u001b[0m\n",
      "\u001b[34massigner=dict(\u001b[0m\n",
      "\u001b[34mtype='MaxIoUAssigner',\u001b[0m\n",
      "\u001b[34mpos_iou_thr=0.7,\u001b[0m\n",
      "\u001b[34mneg_iou_thr=0.3,\u001b[0m\n",
      "\u001b[34mmin_pos_iou=0.3,\u001b[0m\n",
      "\u001b[34mmatch_low_quality=True,\u001b[0m\n",
      "\u001b[34mignore_iof_thr=-1),\u001b[0m\n",
      "\u001b[34msampler=dict(\u001b[0m\n",
      "\u001b[34mtype='RandomSampler',\u001b[0m\n",
      "\u001b[34mnum=256,\u001b[0m\n",
      "\u001b[34mpos_fraction=0.5,\u001b[0m\n",
      "\u001b[34mneg_pos_ub=-1,\u001b[0m\n",
      "\u001b[34madd_gt_as_proposals=False),\u001b[0m\n",
      "\u001b[34mallowed_border=-1,\u001b[0m\n",
      "\u001b[34mpos_weight=-1,\u001b[0m\n",
      "\u001b[34mdebug=False),\u001b[0m\n",
      "\u001b[34mrpn_proposal=dict(\u001b[0m\n",
      "\u001b[34mnms_across_levels=False,\u001b[0m\n",
      "\u001b[34mnms_pre=2000,\u001b[0m\n",
      "\u001b[34mnms_post=1000,\u001b[0m\n",
      "\u001b[34mmax_num=1000,\u001b[0m\n",
      "\u001b[34mnms_thr=0.7,\u001b[0m\n",
      "\u001b[34mmin_bbox_size=0),\u001b[0m\n",
      "\u001b[34mrcnn=dict(\u001b[0m\n",
      "\u001b[34massigner=dict(\u001b[0m\n",
      "\u001b[34mtype='MaxIoUAssigner',\u001b[0m\n",
      "\u001b[34mpos_iou_thr=0.5,\u001b[0m\n",
      "\u001b[34mneg_iou_thr=0.5,\u001b[0m\n",
      "\u001b[34mmin_pos_iou=0.5,\u001b[0m\n",
      "\u001b[34mmatch_low_quality=True,\u001b[0m\n",
      "\u001b[34mignore_iof_thr=-1),\u001b[0m\n",
      "\u001b[34msampler=dict(\u001b[0m\n",
      "\u001b[34mtype='RandomSampler',\u001b[0m\n",
      "\u001b[34mnum=512,\u001b[0m\n",
      "\u001b[34mpos_fraction=0.25,\u001b[0m\n",
      "\u001b[34mneg_pos_ub=-1,\u001b[0m\n",
      "\u001b[34madd_gt_as_proposals=True),\u001b[0m\n",
      "\u001b[34mmask_size=28,\u001b[0m\n",
      "\u001b[34mpos_weight=-1,\u001b[0m\n",
      "\u001b[34mdebug=False))\u001b[0m\n",
      "\u001b[34mtest_cfg = dict(\u001b[0m\n",
      "\u001b[34mrpn=dict(\u001b[0m\n",
      "\u001b[34mnms_across_levels=False,\u001b[0m\n",
      "\u001b[34mnms_pre=1000,\u001b[0m\n",
      "\u001b[34mnms_post=1000,\u001b[0m\n",
      "\u001b[34mmax_num=1000,\u001b[0m\n",
      "\u001b[34mnms_thr=0.7,\u001b[0m\n",
      "\u001b[34mmin_bbox_size=0),\u001b[0m\n",
      "\u001b[34mrcnn=dict(\u001b[0m\n",
      "\u001b[34mscore_thr=0.05,\u001b[0m\n",
      "\u001b[34mnms=dict(type='nms', iou_threshold=0.5),\u001b[0m\n",
      "\u001b[34mmax_per_img=100,\u001b[0m\n",
      "\u001b[34mmask_thr_binary=0.5))\u001b[0m\n",
      "\u001b[34mdataset_type = 'CocoDataset'\u001b[0m\n",
      "\u001b[34mdata_root = '/opt/ml/input/data/training'\u001b[0m\n",
      "\u001b[34mimg_norm_cfg = dict(\u001b[0m\n",
      "\u001b[34mmean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\u001b[0m\n",
      "\u001b[34mtrain_pipeline = [\u001b[0m\n",
      "\u001b[34mdict(type='LoadImageFromFile'),\u001b[0m\n",
      "\u001b[34mdict(type='LoadAnnotations', with_bbox=True, with_mask=True),\u001b[0m\n",
      "\u001b[34mdict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\u001b[0m\n",
      "\u001b[34mdict(type='RandomFlip', flip_ratio=0.5),\u001b[0m\n",
      "\u001b[34mdict(\u001b[0m\n",
      "\u001b[34mtype='Normalize',\u001b[0m\n",
      "\u001b[34mmean=[123.675, 116.28, 103.53],\u001b[0m\n",
      "\u001b[34mstd=[58.395, 57.12, 57.375],\u001b[0m\n",
      "\u001b[34mto_rgb=True),\u001b[0m\n",
      "\u001b[34mdict(type='Pad', size_divisor=32),\u001b[0m\n",
      "\u001b[34mdict(type='DefaultFormatBundle'),\u001b[0m\n",
      "\u001b[34mdict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\u001b[0m\n",
      "\u001b[34m]\u001b[0m\n",
      "\u001b[34mtest_pipeline = [\u001b[0m\n",
      "\u001b[34mdict(type='LoadImageFromFile'),\u001b[0m\n",
      "\u001b[34mdict(\u001b[0m\n",
      "\u001b[34mtype='MultiScaleFlipAug',\u001b[0m\n",
      "\u001b[34mimg_scale=(1333, 800),\u001b[0m\n",
      "\u001b[34mflip=False,\u001b[0m\n",
      "\u001b[34mtransforms=[\u001b[0m\n",
      "\u001b[34mdict(type='Resize', keep_ratio=True),\u001b[0m\n",
      "\u001b[34mdict(type='RandomFlip'),\u001b[0m\n",
      "\u001b[34mdict(\u001b[0m\n",
      "\u001b[34mtype='Normalize',\u001b[0m\n",
      "\u001b[34mmean=[123.675, 116.28, 103.53],\u001b[0m\n",
      "\u001b[34mstd=[58.395, 57.12, 57.375],\u001b[0m\n",
      "\u001b[34mto_rgb=True),\u001b[0m\n",
      "\u001b[34mdict(type='Pad', size_divisor=32),\u001b[0m\n",
      "\u001b[34mdict(type='ImageToTensor', keys=['img']),\u001b[0m\n",
      "\u001b[34mdict(type='Collect', keys=['img'])\u001b[0m\n",
      "\u001b[34m])\u001b[0m\n",
      "\u001b[34m]\u001b[0m\n",
      "\u001b[34mdata = dict(\u001b[0m\n",
      "\u001b[34msamples_per_gpu=2,\u001b[0m\n",
      "\u001b[34mworkers_per_gpu=2,\u001b[0m\n",
      "\u001b[34mtrain=dict(\u001b[0m\n",
      "\u001b[34mtype='CocoDataset',\u001b[0m\n",
      "\u001b[34mann_file=\u001b[0m\n",
      "\u001b[34m'/opt/ml/input/data/training/annotations/instances_train2017.json',\u001b[0m\n",
      "\u001b[34mimg_prefix='/opt/ml/input/data/training/train2017',\u001b[0m\n",
      "\u001b[34mpipeline=[\u001b[0m\n",
      "\u001b[34mdict(type='LoadImageFromFile'),\u001b[0m\n",
      "\u001b[34mdict(type='LoadAnnotations', with_bbox=True, with_mask=True),\u001b[0m\n",
      "\u001b[34mdict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\u001b[0m\n",
      "\u001b[34mdict(type='RandomFlip', flip_ratio=0.5),\u001b[0m\n",
      "\u001b[34mdict(\u001b[0m\n",
      "\u001b[34mtype='Normalize',\u001b[0m\n",
      "\u001b[34mmean=[123.675, 116.28, 103.53],\u001b[0m\n",
      "\u001b[34mstd=[58.395, 57.12, 57.375],\u001b[0m\n",
      "\u001b[34mto_rgb=True),\u001b[0m\n",
      "\u001b[34mdict(type='Pad', size_divisor=32),\u001b[0m\n",
      "\u001b[34mdict(type='DefaultFormatBundle'),\u001b[0m\n",
      "\u001b[34mdict(\u001b[0m\n",
      "\u001b[34mtype='Collect',\u001b[0m\n",
      "\u001b[34mkeys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\u001b[0m\n",
      "\u001b[34m]),\u001b[0m\n",
      "\u001b[34mval=dict(\u001b[0m\n",
      "\u001b[34mtype='CocoDataset',\u001b[0m\n",
      "\u001b[34mann_file=\u001b[0m\n",
      "\u001b[34m'/opt/ml/input/data/training/annotations/instances_val2017.json',\u001b[0m\n",
      "\u001b[34mimg_prefix='/opt/ml/input/data/training/val2017',\u001b[0m\n",
      "\u001b[34mpipeline=[\u001b[0m\n",
      "\u001b[34mdict(type='LoadImageFromFile'),\u001b[0m\n",
      "\u001b[34mdict(\u001b[0m\n",
      "\u001b[34mtype='MultiScaleFlipAug',\u001b[0m\n",
      "\u001b[34mimg_scale=(1333, 800),\u001b[0m\n",
      "\u001b[34mflip=False,\u001b[0m\n",
      "\u001b[34mtransforms=[\u001b[0m\n",
      "\u001b[34mdict(type='Resize', keep_ratio=True),\u001b[0m\n",
      "\u001b[34mdict(type='RandomFlip'),\u001b[0m\n",
      "\u001b[34mdict(\u001b[0m\n",
      "\u001b[34mtype='Normalize',\u001b[0m\n",
      "\u001b[34mmean=[123.675, 116.28, 103.53],\u001b[0m\n",
      "\u001b[34mstd=[58.395, 57.12, 57.375],\u001b[0m\n",
      "\u001b[34mto_rgb=True),\u001b[0m\n",
      "\u001b[34mdict(type='Pad', size_divisor=32),\u001b[0m\n",
      "\u001b[34mdict(type='ImageToTensor', keys=['img']),\u001b[0m\n",
      "\u001b[34mdict(type='Collect', keys=['img'])\u001b[0m\n",
      "\u001b[34m])\u001b[0m\n",
      "\u001b[34m]),\u001b[0m\n",
      "\u001b[34mtest=dict(\u001b[0m\n",
      "\u001b[34mtype='CocoDataset',\u001b[0m\n",
      "\u001b[34mann_file=\u001b[0m\n",
      "\u001b[34m'/opt/ml/input/data/training/annotations/instances_val2017.json',\u001b[0m\n",
      "\u001b[34mimg_prefix='/opt/ml/input/data/training/val2017',\u001b[0m\n",
      "\u001b[34mpipeline=[\u001b[0m\n",
      "\u001b[34mdict(type='LoadImageFromFile'),\u001b[0m\n",
      "\u001b[34mdict(\u001b[0m\n",
      "\u001b[34mtype='MultiScaleFlipAug',\u001b[0m\n",
      "\u001b[34mimg_scale=(1333, 800),\u001b[0m\n",
      "\u001b[34mflip=False,\u001b[0m\n",
      "\u001b[34mtransforms=[\u001b[0m\n",
      "\u001b[34mdict(type='Resize', keep_ratio=True),\u001b[0m\n",
      "\u001b[34mdict(type='RandomFlip'),\u001b[0m\n",
      "\u001b[34mdict(\u001b[0m\n",
      "\u001b[34mtype='Normalize',\u001b[0m\n",
      "\u001b[34mmean=[123.675, 116.28, 103.53],\u001b[0m\n",
      "\u001b[34mstd=[58.395, 57.12, 57.375],\u001b[0m\n",
      "\u001b[34mto_rgb=True),\u001b[0m\n",
      "\u001b[34mdict(type='Pad', size_divisor=32),\u001b[0m\n",
      "\u001b[34mdict(type='ImageToTensor', keys=['img']),\u001b[0m\n",
      "\u001b[34mdict(type='Collect', keys=['img'])\u001b[0m\n",
      "\u001b[34m])\u001b[0m\n",
      "\u001b[34m]))\u001b[0m\n",
      "\u001b[34mevaluation = dict(metric=['bbox', 'segm'])\u001b[0m\n",
      "\u001b[34moptimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\u001b[0m\n",
      "\u001b[34moptimizer_config = dict(grad_clip=None)\u001b[0m\n",
      "\u001b[34mlr_config = dict(\u001b[0m\n",
      "\u001b[34mpolicy='step',\u001b[0m\n",
      "\u001b[34mwarmup='linear',\u001b[0m\n",
      "\u001b[34mwarmup_iters=500,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.001,\u001b[0m\n",
      "\u001b[34mstep=[8, 11])\u001b[0m\n",
      "\u001b[34mtotal_epochs = 12\u001b[0m\n",
      "\u001b[34mcheckpoint_config = dict(interval=1)\u001b[0m\n",
      "\u001b[34mlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\u001b[0m\n",
      "\u001b[34mdist_params = dict(backend='nccl')\u001b[0m\n",
      "\u001b[34mlog_level = 'INFO'\u001b[0m\n",
      "\u001b[34mload_from = None\u001b[0m\n",
      "\u001b[34mresume_from = None\u001b[0m\n",
      "\u001b[34mworkflow = [('train', 1)]\u001b[0m\n",
      "\u001b[34mwork_dir = './work_dirs/updated_config'\u001b[0m\n",
      "\u001b[34mgpu_ids = range(0, 1)\n",
      "\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:43,362 - mmdet - INFO - load model from: torchvision://resnet50\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\u001b[0m\n",
      "\u001b[34m0%|          | 0.00/97.8M [00:00<?, ?B/s]#015  2%|▏         | 1.72M/97.8M [00:00<00:05, 17.9MB/s]#015 10%|▉         | 9.71M/97.8M [00:00<00:03, 23.5MB/s]#015 18%|█▊        | 17.8M/97.8M [00:00<00:02, 30.0MB/s]#015 27%|██▋       | 25.9M/97.8M [00:00<00:02, 37.2MB/s]#015 32%|███▏      | 31.4M/97.8M [00:00<00:01, 38.6MB/s]#015 37%|███▋      | 36.4M/97.8M [00:00<00:01, 34.8MB/s]#015 42%|████▏     | 40.8M/97.8M [00:00<00:01, 30.4MB/s]#015 46%|████▌     | 44.5M/97.8M [00:01<00:01, 29.4MB/s]#015 49%|████▉     | 47.9M/97.8M [00:01<00:02, 23.3MB/s]#015 52%|█████▏    | 50.7M/97.8M [00:01<00:02, 22.0MB/s]#015 54%|█████▍    | 53.2M/97.8M [00:01<00:02, 20.8MB/s]#015 57%|█████▋    | 55.5M/97.8M [00:01<00:02, 19.6MB/s]#015 59%|█████▉    | 58.1M/97.8M [00:01<00:02, 20.7MB/s]#015 62%|██████▏   | 60.2M/97.8M [00:01<00:01, 20.3MB/s]#015 64%|██████▍   | 62.9M/97.8M [00:02<00:01, 22.1MB/s]#015 67%|██████▋   | 65.3M/97.8M [00:02<00:01, 23.0MB/s]#015 70%|██████▉   | 68.2M/97.8M [00:02<00:01, 24.7MB/s]#015 72%|███████▏  | 70.7M/97.8M [00:02<00:01, 23.5MB/s]#015 75%|███████▌  | 73.5M/97.8M [00:02<00:01, 24.9MB/s]#015 78%|███████▊  | 75.9M/97.8M [00:02<00:01, 19.9MB/s]#015 80%|███████▉  | 78.0M/97.8M [00:02<00:01, 18.3MB/s]#015 82%|████████▏ | 80.5M/97.8M [00:02<00:00, 20.0MB/s]#015 85%|████████▌ | 83.3M/97.8M [00:03<00:00, 22.1MB/s]#015 88%|████████▊ | 85.6M/97.8M [00:03<00:00, 22.4MB/s]#015 90%|█████████ | 88.0M/97.8M [00:03<00:00, 23.2MB/s]#015 93%|█████████▎| 90.7M/97.8M [00:03<00:00, 24.5MB/s]#015 95%|█████████▌| 93.1M/97.8M [00:03<00:00, 22.1MB/s]#015 98%|█████████▊| 95.4M/97.8M [00:03<00:00, 20.4MB/s]#015100%|██████████| 97.8M/97.8M [00:03<00:00, 27.8MB/s]\u001b[0m\n",
      "\u001b[35m0%|          | 0.00/97.8M [00:00<?, ?B/s]#015  1%|          | 1.18M/97.8M [00:00<00:08, 12.3MB/s]#015  5%|▌         | 4.92M/97.8M [00:00<00:06, 15.4MB/s]#015  8%|▊         | 7.73M/97.8M [00:00<00:05, 18.0MB/s]#015 11%|█         | 10.5M/97.8M [00:00<00:04, 20.3MB/s]#015 13%|█▎        | 12.6M/97.8M [00:00<00:04, 19.7MB/s]#015 16%|█▌        | 15.4M/97.8M [00:00<00:03, 21.8MB/s]#015 19%|█▊        | 18.2M/97.8M [00:00<00:03, 23.6MB/s]#015 21%|██▏       | 20.8M/97.8M [00:00<00:03, 24.4MB/s]#015 24%|██▍       | 23.6M/97.8M [00:00<00:03, 25.6MB/s]#015 27%|██▋       | 26.5M/97.8M [00:01<00:02, 26.7MB/s]#015 30%|███       | 29.4M/97.8M [00:01<00:02, 27.5MB/s]#015 33%|███▎      | 32.0M/97.8M [00:01<00:02, 27.1MB/s]#015 36%|███▌      | 34.8M/97.8M [00:01<00:02, 27.6MB/s]#015 38%|███▊      | 37.5M/97.8M [00:01<00:02, 25.6MB/s]#015 41%|████      | 40.1M/97.8M [00:01<00:02, 26.0MB/s]#015 44%|████▎     | 42.7M/97.8M [00:01<00:02, 26.4MB/s]#015 46%|████▋     | 45.3M/97.8M [00:01<00:02, 26.3MB/s]#015 49%|████▉     | 47.8M/97.8M [00:01<00:02, 20.8MB/s]#015 51%|█████     | 50.0M/97.8M [00:02<00:02, 19.7MB/s]#015 54%|█████▍    | 52.7M/97.8M [00:02<00:02, 21.6MB/s]#015 56%|█████▌    | 54.9M/97.8M [00:02<00:02, 19.1MB/s]#015 58%|█████▊    | 56.9M/97.8M [00:02<00:02, 19.4MB/s]#015 60%|██████    | 58.8M/97.8M [00:02<00:02, 18.4MB/s]#015 63%|██████▎   | 61.5M/97.8M [00:02<00:01, 20.4MB/s]#015 66%|██████▌   | 64.1M/97.8M [00:02<00:01, 22.0MB/s]#015 68%|██████▊   | 66.8M/97.8M [00:02<00:01, 23.5MB/s]#015 71%|███████   | 69.2M/97.8M [00:02<00:01, 22.9MB/s]#015 74%|███████▎  | 71.9M/97.8M [00:03<00:01, 24.2MB/s]#015 76%|███████▌  | 74.2M/97.8M [00:03<00:01, 24.0MB/s]#015 78%|███████▊  | 76.6M/97.8M [00:03<00:01, 20.4MB/s]#015 80%|████████  | 78.7M/97.8M [00:03<00:01, 18.3MB/s]#015 83%|████████▎ | 81.3M/97.8M [00:03<00:00, 20.3MB/s]#015 86%|████████▌ | 83.6M/97.8M [00:03<00:00, 21.3MB/s]#015 88%|████████▊ | 86.2M/97.8M [00:03<00:00, 22.8MB/s]#015 91%|█████████ | 88.7M/97.8M [00:03<00:00, 23.5MB/s]#015 93%|█████████▎| 91.4M/97.8M [00:04<00:00, 24.7MB/s]#015 96%|█████████▌| 93.8M/97.8M [00:04<00:00, 22.4MB/s]#015 98%|█████████▊| 96.0M/97.8M [00:04<00:00, 20.5MB/s]#015100%|██████████| 97.8M/97.8M [00:04<00:00, 23.5MB/s]\u001b[0m\n",
      "\u001b[34mNCCL version 2.4.8+cuda10.2\u001b[0m\n",
      "\u001b[34m2020-07-25 22:55:51,441 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\u001b[0m\n",
      "\u001b[34munexpected key in source state_dict: fc.weight, fc.bias\n",
      "\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mDone (t=18.48s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mDone (t=18.50s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mDone (t=18.53s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mDone (t=18.70s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mDone (t=18.70s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mDone (t=18.80s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mDone (t=18.89s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mDone (t=19.17s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[34mDone (t=19.22s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mDone (t=19.26s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mDone (t=19.29s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mDone (t=19.34s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mDone (t=19.55s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mDone (t=19.35s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mDone (t=19.39s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mDone (t=19.44s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mloading annotations into memory...\u001b[0m\n",
      "\u001b[35mDone (t=2.20s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mDone (t=2.29s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mDone (t=2.06s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mDone (t=2.05s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mDone (t=2.06s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mDone (t=0.45s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mDone (t=2.52s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[35mDone (t=2.85s)\u001b[0m\n",
      "\u001b[35mcreating index...\u001b[0m\n",
      "\u001b[35mindex created!\u001b[0m\n",
      "\u001b[34mDone (t=0.45s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34m2020-07-25 22:56:15,834 - mmdet - INFO - Start running, host: root@algo-1, work_dir: /opt/ml/code/work_dirs/updated_config\u001b[0m\n",
      "\u001b[34m2020-07-25 22:56:15,834 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs\u001b[0m\n",
      "\u001b[34mDone (t=2.10s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mDone (t=2.21s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mDone (t=2.09s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mDone (t=2.09s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mDone (t=2.21s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mDone (t=2.06s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mDone (t=2.79s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34m2020-07-25 22:57:21,753 - mmdet - INFO - Epoch [1][50/3665]#011lr: 1.978e-03, eta: 16:04:02, time: 1.317, data_time: 0.856, memory: 3991, loss_rpn_cls: 0.5778, loss_rpn_bbox: 0.1057, loss_cls: 1.0740, acc: 87.6870, loss_bbox: 0.0677, loss_mask: 0.7657, loss: 2.5909\u001b[0m\n",
      "\u001b[34m2020-07-25 22:57:47,432 - mmdet - INFO - Epoch [1][100/3665]#011lr: 3.976e-03, eta: 11:09:11, time: 0.513, data_time: 0.050, memory: 4172, loss_rpn_cls: 0.2099, loss_rpn_bbox: 0.0991, loss_cls: 0.5094, acc: 93.8983, loss_bbox: 0.2097, loss_mask: 0.6877, loss: 1.7158\u001b[0m\n",
      "\u001b[34m2020-07-25 22:58:12,970 - mmdet - INFO - Epoch [1][150/3665]#011lr: 5.974e-03, eta: 9:30:03, time: 0.511, data_time: 0.056, memory: 4172, loss_rpn_cls: 0.1647, loss_rpn_bbox: 0.0970, loss_cls: 0.4994, acc: 93.3624, loss_bbox: 0.2302, loss_mask: 0.6642, loss: 1.6556\u001b[0m\n",
      "\u001b[34m2020-07-25 22:58:39,162 - mmdet - INFO - Epoch [1][200/3665]#011lr: 7.972e-03, eta: 8:42:25, time: 0.523, data_time: 0.051, memory: 4292, loss_rpn_cls: 0.1320, loss_rpn_bbox: 0.0945, loss_cls: 0.4840, acc: 91.9410, loss_bbox: 0.2901, loss_mask: 0.6278, loss: 1.6283\u001b[0m\n",
      "\u001b[34m2020-07-25 22:59:05,219 - mmdet - INFO - Epoch [1][250/3665]#011lr: 9.970e-03, eta: 8:13:29, time: 0.522, data_time: 0.051, memory: 4292, loss_rpn_cls: 0.1166, loss_rpn_bbox: 0.0931, loss_cls: 0.5044, acc: 91.2208, loss_bbox: 0.3253, loss_mask: 0.5926, loss: 1.6319\u001b[0m\n",
      "\u001b[34m2020-07-25 22:59:31,135 - mmdet - INFO - Epoch [1][300/3665]#011lr: 1.197e-02, eta: 7:53:43, time: 0.519, data_time: 0.077, memory: 4383, loss_rpn_cls: 0.1059, loss_rpn_bbox: 0.0875, loss_cls: 0.5368, acc: 90.3888, loss_bbox: 0.3584, loss_mask: 0.5667, loss: 1.6552\u001b[0m\n",
      "\u001b[34m2020-07-25 22:59:57,364 - mmdet - INFO - Epoch [1][350/3665]#011lr: 1.397e-02, eta: 7:40:03, time: 0.524, data_time: 0.053, memory: 4383, loss_rpn_cls: 0.0987, loss_rpn_bbox: 0.0862, loss_cls: 0.5300, acc: 90.4637, loss_bbox: 0.3529, loss_mask: 0.5351, loss: 1.6030\u001b[0m\n",
      "\u001b[34m2020-07-25 23:00:23,871 - mmdet - INFO - Epoch [1][400/3665]#011lr: 1.596e-02, eta: 7:30:12, time: 0.530, data_time: 0.063, memory: 4399, loss_rpn_cls: 0.0958, loss_rpn_bbox: 0.0859, loss_cls: 0.5485, acc: 89.5695, loss_bbox: 0.3869, loss_mask: 0.4996, loss: 1.6167\u001b[0m\n",
      "\u001b[34m2020-07-25 23:00:50,285 - mmdet - INFO - Epoch [1][450/3665]#011lr: 1.796e-02, eta: 7:22:18, time: 0.528, data_time: 0.053, memory: 4399, loss_rpn_cls: 0.0915, loss_rpn_bbox: 0.0838, loss_cls: 0.5215, acc: 89.7349, loss_bbox: 0.3813, loss_mask: 0.4848, loss: 1.5629\u001b[0m\n",
      "\u001b[34m2020-07-25 23:01:16,726 - mmdet - INFO - Epoch [1][500/3665]#011lr: 1.996e-02, eta: 7:15:55, time: 0.528, data_time: 0.045, memory: 4401, loss_rpn_cls: 0.0861, loss_rpn_bbox: 0.0845, loss_cls: 0.5138, acc: 89.4012, loss_bbox: 0.3883, loss_mask: 0.4707, loss: 1.5435\u001b[0m\n",
      "\u001b[34m2020-07-25 23:01:43,183 - mmdet - INFO - Epoch [1][550/3665]#011lr: 2.000e-02, eta: 7:10:38, time: 0.529, data_time: 0.047, memory: 4403, loss_rpn_cls: 0.0830, loss_rpn_bbox: 0.0778, loss_cls: 0.4970, acc: 89.5526, loss_bbox: 0.3737, loss_mask: 0.4520, loss: 1.4835\u001b[0m\n",
      "\u001b[34m2020-07-25 23:02:09,656 - mmdet - INFO - Epoch [1][600/3665]#011lr: 2.000e-02, eta: 7:06:15, time: 0.530, data_time: 0.049, memory: 4403, loss_rpn_cls: 0.0886, loss_rpn_bbox: 0.0805, loss_cls: 0.4843, acc: 89.5598, loss_bbox: 0.3693, loss_mask: 0.4452, loss: 1.4679\u001b[0m\n",
      "\u001b[34m2020-07-25 23:02:36,156 - mmdet - INFO - Epoch [1][650/3665]#011lr: 2.000e-02, eta: 7:02:25, time: 0.529, data_time: 0.071, memory: 4404, loss_rpn_cls: 0.0827, loss_rpn_bbox: 0.0806, loss_cls: 0.4579, acc: 89.4702, loss_bbox: 0.3708, loss_mask: 0.4350, loss: 1.4270\u001b[0m\n",
      "\u001b[34m2020-07-25 23:03:02,775 - mmdet - INFO - Epoch [1][700/3665]#011lr: 2.000e-02, eta: 6:59:13, time: 0.533, data_time: 0.052, memory: 4432, loss_rpn_cls: 0.0782, loss_rpn_bbox: 0.0777, loss_cls: 0.4401, acc: 89.5042, loss_bbox: 0.3616, loss_mask: 0.4243, loss: 1.3820\u001b[0m\n",
      "\u001b[34m2020-07-25 23:03:29,483 - mmdet - INFO - Epoch [1][750/3665]#011lr: 2.000e-02, eta: 6:56:29, time: 0.534, data_time: 0.045, memory: 4432, loss_rpn_cls: 0.0808, loss_rpn_bbox: 0.0801, loss_cls: 0.4379, acc: 89.5817, loss_bbox: 0.3581, loss_mask: 0.4274, loss: 1.3842\u001b[0m\n",
      "\u001b[34m2020-07-25 23:03:56,182 - mmdet - INFO - Epoch [1][800/3665]#011lr: 2.000e-02, eta: 6:54:02, time: 0.534, data_time: 0.056, memory: 4432, loss_rpn_cls: 0.0767, loss_rpn_bbox: 0.0777, loss_cls: 0.4419, acc: 89.4492, loss_bbox: 0.3593, loss_mask: 0.4164, loss: 1.3720\u001b[0m\n",
      "\u001b[34m2020-07-25 23:04:22,666 - mmdet - INFO - Epoch [1][850/3665]#011lr: 2.000e-02, eta: 6:51:37, time: 0.530, data_time: 0.062, memory: 4432, loss_rpn_cls: 0.0721, loss_rpn_bbox: 0.0760, loss_cls: 0.4168, acc: 89.6450, loss_bbox: 0.3544, loss_mask: 0.4048, loss: 1.3241\u001b[0m\n",
      "\u001b[34m2020-07-25 23:04:48,915 - mmdet - INFO - Epoch [1][900/3665]#011lr: 2.000e-02, eta: 6:49:15, time: 0.525, data_time: 0.053, memory: 4432, loss_rpn_cls: 0.0726, loss_rpn_bbox: 0.0738, loss_cls: 0.4115, acc: 89.7723, loss_bbox: 0.3493, loss_mask: 0.4074, loss: 1.3146\u001b[0m\n",
      "\u001b[34m2020-07-25 23:05:15,684 - mmdet - INFO - Epoch [1][950/3665]#011lr: 2.000e-02, eta: 6:47:27, time: 0.535, data_time: 0.056, memory: 4433, loss_rpn_cls: 0.0740, loss_rpn_bbox: 0.0748, loss_cls: 0.4170, acc: 89.8840, loss_bbox: 0.3322, loss_mask: 0.3979, loss: 1.2959\u001b[0m\n",
      "\u001b[34m2020-07-25 23:05:41,978 - mmdet - INFO - Epoch [1][1000/3665]#011lr: 2.000e-02, eta: 6:45:28, time: 0.526, data_time: 0.056, memory: 4433, loss_rpn_cls: 0.0704, loss_rpn_bbox: 0.0749, loss_cls: 0.4044, acc: 89.6919, loss_bbox: 0.3465, loss_mask: 0.3950, loss: 1.2912\u001b[0m\n",
      "\u001b[34m2020-07-25 23:06:08,359 - mmdet - INFO - Epoch [1][1050/3665]#011lr: 2.000e-02, eta: 6:43:41, time: 0.528, data_time: 0.054, memory: 4433, loss_rpn_cls: 0.0717, loss_rpn_bbox: 0.0736, loss_cls: 0.4038, acc: 89.6521, loss_bbox: 0.3457, loss_mask: 0.3948, loss: 1.2896\u001b[0m\n",
      "\u001b[34m2020-07-25 23:06:34,823 - mmdet - INFO - Epoch [1][1100/3665]#011lr: 2.000e-02, eta: 6:42:04, time: 0.529, data_time: 0.060, memory: 4433, loss_rpn_cls: 0.0668, loss_rpn_bbox: 0.0719, loss_cls: 0.3851, acc: 89.9727, loss_bbox: 0.3351, loss_mask: 0.3895, loss: 1.2485\u001b[0m\n",
      "\u001b[34m2020-07-25 23:07:01,285 - mmdet - INFO - Epoch [1][1150/3665]#011lr: 2.000e-02, eta: 6:40:34, time: 0.529, data_time: 0.060, memory: 4433, loss_rpn_cls: 0.0725, loss_rpn_bbox: 0.0786, loss_cls: 0.3963, acc: 89.4929, loss_bbox: 0.3505, loss_mask: 0.3898, loss: 1.2877\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "est = sagemaker.estimator.Estimator(image,\n",
    "                                          role=role,\n",
    "                                          train_instance_count=2,\n",
    "                                          train_instance_type='ml.p3.16xlarge',\n",
    "#                                           train_instance_type=\"local_gpu\", # use local_gpu for quick troubleshooting\n",
    "                                          train_volume_size=100,\n",
    "                                          output_path=\"s3://{}/{}\".format(sess.default_bucket(), prefix_output),\n",
    "                                          metric_definitions = metrics,\n",
    "                                          hyperparameters = hyperparameters, \n",
    "#                                           sagemaker_session=sagemaker.LocalSession()\n",
    "                                          sagemaker_session=sess\n",
    ")\n",
    "\n",
    "est.fit({\"training\" : \"s3://coco2017-2a27f/coco\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
