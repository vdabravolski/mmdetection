{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "# login to Sagemaker ECR with Deep Learning Containers\n",
    "!aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-2.amazonaws.com\n",
    "# login to your private ECR\n",
    "!aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 553020858742.dkr.ecr.us-east-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! pygmentize -l docker Dockerfile.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  553.7MB\n",
      "Step 1/13 : FROM 763104351884.dkr.ecr.us-east-2.amazonaws.com/pytorch-training:1.5.0-gpu-py36-cu101-ubuntu16.04\n",
      " ---> 47cd15520b75\n",
      "Step 2/13 : LABEL author=\"vadimd@amazon.com\"\n",
      " ---> Using cache\n",
      " ---> 922dae94eea7\n",
      "Step 3/13 : WORKDIR /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 1e829cda7967\n",
      "Step 4/13 : RUN pip install --upgrade --force-reinstall  torch torchvision cython\n",
      " ---> Using cache\n",
      " ---> de5e1c07154c\n",
      "Step 5/13 : RUN pip install mmcv-full==latest+torch1.5.0+cu101 -f https://openmmlab.oss-accelerate.aliyuncs.com/mmcv/dist/index.html\n",
      " ---> Using cache\n",
      " ---> 73fa494e5c7a\n",
      "Step 6/13 : RUN git clone https://github.com/open-mmlab/mmdetection\n",
      " ---> Using cache\n",
      " ---> 57350fc7c079\n",
      "Step 7/13 : RUN cd mmdetection/ &&     pip install -e .\n",
      " ---> Using cache\n",
      " ---> b70d3e0c1052\n",
      "Step 8/13 : ENV MKL_THREADING_LAYER GNU\n",
      " ---> Using cache\n",
      " ---> 0f41a7766664\n",
      "Step 9/13 : ENV MMDETECTION /opt/ml/code/mmdetection\n",
      " ---> Using cache\n",
      " ---> 8b71c05d888c\n",
      "Step 10/13 : COPY container_training /opt/ml/code\n",
      " ---> cdffbbe6f2a3\n",
      "Step 11/13 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Running in 51103b1d74a1\n",
      "Removing intermediate container 51103b1d74a1\n",
      " ---> 93ea3a7ee92b\n",
      "Step 12/13 : ENV SAGEMAKER_PROGRAM mmdetection_train.py\n",
      " ---> Running in 3288dce72a96\n",
      "Removing intermediate container 3288dce72a96\n",
      " ---> 4d9ca7d053db\n",
      "Step 13/13 : WORKDIR /\n",
      " ---> Running in e16049b2aa7b\n",
      "Removing intermediate container e16049b2aa7b\n",
      " ---> b4b7b6bfa0aa\n",
      "Successfully built b4b7b6bfa0aa\n",
      "Successfully tagged mmdetection-training:latest\n",
      "The push refers to repository [553020858742.dkr.ecr.us-east-2.amazonaws.com/mmdetection-training]\n",
      "\n",
      "\u001b[1B9b310ba5: Preparing \n",
      "\u001b[1Beff3b448: Preparing \n",
      "\u001b[1B52d289f5: Preparing \n",
      "\u001b[1B552c64f8: Preparing \n",
      "\u001b[1B500d3ac7: Preparing \n",
      "\u001b[1B0eab7642: Preparing \n",
      "\u001b[1Bdc6eccf1: Preparing \n",
      "\u001b[1Be8cb8ead: Preparing \n",
      "\u001b[1B18b6f784: Preparing \n",
      "\u001b[1Bbe96fc82: Preparing \n",
      "\u001b[1B2b332e53: Preparing \n",
      "\u001b[1Bc6e1c93f: Preparing \n",
      "\u001b[1B8af0cced: Preparing \n",
      "\u001b[1Ba1e058e6: Preparing \n",
      "\u001b[1Ba7e2d141: Preparing \n",
      "\u001b[1B891256c7: Preparing \n",
      "\u001b[1B4275da12: Preparing \n",
      "\u001b[1B8601ef26: Preparing \n",
      "\u001b[1B03245374: Preparing \n",
      "\u001b[1Be3aaa392: Preparing \n",
      "\u001b[15Bc6eccf1: Waiting g \n",
      "\u001b[12Bb332e53: Waiting g \n",
      "\u001b[1B3141886c: Preparing \n",
      "\u001b[8B4275da12: Waiting g \n",
      "\u001b[14B6e1c93f: Waiting g \n",
      "\u001b[9B8601ef26: Waiting g \n",
      "\u001b[6B3589d5b4: Waiting g \n",
      "\u001b[9Be3aaa392: Waiting g \n",
      "\u001b[7B3141886c: Waiting g \n",
      "\u001b[6B20da503d: Waiting g \n",
      "\u001b[26Beab7642: Waiting g \n",
      "\u001b[7Bdadd4466: Waiting g \n",
      "\u001b[7B74e50f52: Waiting g \n",
      "\u001b[34Bb310ba5: Pushed lready exists 9kB\u001b[26A\u001b[2K\u001b[21A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[3A\u001b[2Klatest: digest: sha256:3f1ce6646da9b0927ba32da1550618296db1701181c2ef94e4d6d41bcce54a48 size: 7472\n"
     ]
    }
   ],
   "source": [
    "! ./build_and_push.sh mmdetection-training latest Dockerfile.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "region = \"us-east-2\"\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "prefix_input = 'mmdetection-input'\n",
    "prefix_output = 'mmdetection-ouput'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = \"mmdetection-training\" # your container name\n",
    "tag = \"latest\"\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(account, region, container, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"config-file\" : \"configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\",\n",
    "    \"dataset\" : \"coco\",\n",
    "    # 'options' allows to override individual config values\n",
    "    \"options\" : \"total_epochs=1 cfg.optimizer.lr=0.04\", \n",
    "    \"auto-scale\" : \"false\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    {\n",
    "        \"Name\": \"loss\",\n",
    "        \"Regex\": \".*loss:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_rpn_cls\",\n",
    "        \"Regex\": \".*loss_rpn_cls:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_rpn_bbox\",\n",
    "        \"Regex\": \".*loss_rpn_bbox:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_cls\",\n",
    "        \"Regex\": \".*loss_cls:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"acc\",\n",
    "        \"Regex\": \".*acc:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_bbox\",\n",
    "        \"Regex\": \".*loss_bbox:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_mask\",\n",
    "        \"Regex\": \".*loss_mask:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"lr\",\n",
    "        \"Regex\": \"lr: (-?\\d+.?\\d*(?:[Ee]-\\d+)?)\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Training in SM Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "est = sagemaker.estimator.Estimator(image,\n",
    "                                          role=role,\n",
    "                                          train_instance_count=4,\n",
    "                                          train_instance_type='ml.p3.16xlarge',\n",
    "#                                           train_instance_type=\"local_gpu\", # use local_gpu for quick troubleshooting\n",
    "                                          train_volume_size=100,\n",
    "                                          output_path=\"s3://{}/{}\".format(sess.default_bucket(), prefix_output),\n",
    "                                          metric_definitions = metrics,\n",
    "                                          hyperparameters = hyperparameters, \n",
    "#                                           sagemaker_session=sagemaker.LocalSession()\n",
    "                                          sagemaker_session=sess\n",
    ")\n",
    "\n",
    "est.fit({\"training\" : \"s3://coco2017-2a27f/coco\"}, wait=False)\n",
    "# est.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- test that distributed cluster actually started: requires customization of train.py\n",
    "- [done, but see issue below] ensure scaling of LR based on number of nodes: currently, it's not scaling at all. Need to add some sort of autoscaling policy. \n",
    "- [done] fix workdir (make it a part of config)\n",
    "- [done] test opts: https://github.com/open-mmlab/mmdetection/issues/2646#issuecomment-626100525\n",
    "- [done] add metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Known issues:\n",
    "1. if post-training validation is activated, then following error happens after training is done:\n",
    "\n",
    "    `\n",
    "    File \"/opt/ml/code/mmdetection/tools/train.py\", line 153, in <module>\n",
    "    main()\n",
    "    File \"/opt/ml/code/mmdetection/tools/train.py\", line 149, in main\n",
    "    meta=meta)\n",
    "    File \"/opt/ml/code/mmdetection/mmdet/apis/train.py\", line 128, in train_detector\n",
    "    runner.run(data_loaders, cfg.workflow, cfg.total_epochs)\n",
    "    File \"/opt/conda/lib/python3.6/site-packages/mmcv/runner/epoch_based_runner.py\", line 122, in run\n",
    "    epoch_runner(data_loaders[i], **kwargs)\n",
    "    File \"/opt/conda/lib/python3.6/site-packages/mmcv/runner/epoch_based_runner.py\", line 46, in train\n",
    "    self.call_hook('after_train_epoch')\n",
    "    File \"/opt/conda/lib/python3.6/site-packages/mmcv/runner/base_runner.py\", line 282, in call_hook\n",
    "    getattr(hook, fn_name)(self)\n",
    "    File \"/opt/ml/code/mmdetection/mmdet/core/evaluation/eval_hooks.py\", line 71, in after_train_epoch\n",
    "    gpu_collect=self.gpu_collect)\n",
    "    File \"/opt/ml/code/mmdetection/mmdet/apis/test.py\", line 113, in multi_gpu_test\n",
    "    results = collect_results_cpu(results, len(dataset), tmpdir)\n",
    "    File \"/opt/ml/code/mmdetection/mmdet/apis/test.py\", line 147, in collect_results_cpu\n",
    "    part_list.append(mmcv.load(part_file))\n",
    "    File \"/opt/conda/lib/python3.6/site-packages/mmcv/fileio/io.py\", line 41, in load\n",
    "    obj = handler.load_from_path(file, **kwargs)\n",
    "    File \"/opt/conda/lib/python3.6/site-packages/mmcv/fileio/handlers/pickle_handler.py\", line 14, in load_from_path\n",
    "    filepath, mode='rb', **kwargs)\n",
    "    File \"/opt/conda/lib/python3.6/site-packages/mmcv/fileio/handlers/base.py\", line 20, in load_from_path\n",
    "    with open(filepath, mode) as f:\n",
    "    FileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/output/.eval_hook/part_8.pkl'\n",
    "    Traceback (most recent call last):\n",
    "    File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
    "    \"__main__\", mod_spec)\n",
    "    File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
    "    exec(code, run_globals)\n",
    "    File \"/opt/conda/lib/python3.6/site-packages/torch/distributed/launch.py\", line 263, in <module>\n",
    "    main()\n",
    "    File \"/opt/conda/lib/python3.6/site-packages/torch/distributed/launch.py\", line 259, in main\n",
    "    cmd=cmd)\n",
    "    subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '/opt/ml/code/mmdetection/tools/train.py', '--local_rank=7', '/opt/ml/code/updated_config.py', '--launcher', 'pytorch', '--work-dir', '/opt/ml/output']' returned non-zero exit status 1.\n",
    "    ERROR ExecuteUserScriptError:\n",
    "    Command \"/opt/conda/bin/python mmdetection_train.py --config-file configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py --dataset coco --options total_epochs=1\"\n",
    "    Traceback (most recent call last): File \"mmdetection_train.py\", line 126, in <module> raise subprocess.CalledProcessError(returncode=process.returncode, cmd=joint_cmd)\n",
    "    subprocess.CalledProcessError: Command 'python -m torch.distributed.launch --nnodes 2 --node_rank 0 --nproc_per_node 8 --master_addr algo-1 --master_port 55555 /opt/ml/code/mmdetection/tools/train.py /opt/ml/code/updated_config.py --launcher pytorch --work-dir /opt/ml/output' returned non-zero exit status 1.\n",
    "    `    \n",
    "    \n",
    "2. When scaling of LR and Warmup Steps based on number of training nodes, then loss is not being properly calculated:\n",
    "    `2020-07-26 18:23:57,713 - mmdet - INFO - Epoch [1][1800/1833]#011lr: 8.000e-02, eta: 0:00:20, time: 0.606, data_time: 0.054, memory: 4038, loss_rpn_cls: 0.3840, loss_rpn_bbox: 0.0986, loss_cls: nan, acc: 0.4653, loss_bbox: nan, loss_mask: 0.5701, loss: nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
